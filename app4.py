import streamlit as st
import pandas as pd
import numpy as np
import io,re, sys  # For file handling
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
from catboost import CatBoostRegressor, Pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import StackingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Title
st.title("ğŸ¯ Machine Learning Model Trainer")

# Upload Dataset
st.header("1ï¸âƒ£ Upload Dataset")
uploaded_file = st.file_uploader("Upload your dataset (CSV)", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.title("Welcome to Data Preprocessing")

    if "df_processed" not in st.session_state:
        st.session_state["df_processed"] = df.copy()
    df = st.session_state["df_processed"]

    # Sidebar - Preprocessing Steps
    preprocess_options = ["ğŸ“Š Data Overview","ğŸ” Inconsistency","custom code", "ğŸ“ˆ EDA", "âš™ï¸ Feature Eng", "ğŸ¤– Train Model only"]

    if df.isnull().sum().sum() > 0:
        preprocess_options.insert(1, "âš™ï¸ Handle Missing Values")

    preprocess = st.sidebar.radio("Choose Step", preprocess_options)

    # ğŸ“Š DATA OVERVIEW
    if preprocess == "ğŸ“Š Data Overview":
        st.header("ğŸ“Š Dataset Overview")
        st.write("ğŸ“Œ **Shape:**", df.shape)

        col1, col2 = st.columns(2)
        with col1:
            st.write("ğŸ” **Data Types**")
            dtype_df = pd.DataFrame(df.dtypes, columns=["Data Type"])
            st.dataframe(dtype_df)

        with col2:
            st.write("âš ï¸ **Missing Values Summary:**")
            missing_df = pd.DataFrame(df.isnull().sum(), columns=["Missing Values"])
            st.dataframe(missing_df)

        col1, col2 = st.columns(2)
        with col1:
            st.write("ğŸ“Š **Statistical Summary:**")
            st.dataframe(df.describe())

        with col2:
            st.write("ğŸ“Œ Dataset Information:")
            buffer = io.StringIO()
            df.info(buf=buffer)
            st.text(buffer.getvalue())

        selected_column = st.selectbox("Select a column to check value counts", df.columns)
        if selected_column:
            st.write(f"ğŸ“Š Value Counts for {selected_column}:")
            st.write(df[selected_column].value_counts())

        # âš™ï¸ HANDLE MISSING VALUES
    elif preprocess == "âš™ï¸ Handle Missing Values":
        df_missing = df.copy()
        for col in df_missing.columns:
            if df_missing[col].isnull().sum() > 0:
                st.subheader(f"âš ï¸ Handling Missing Values in **{col}**")
                # Categorical Columns
                if df_missing[col].dtype == 'object':  
                    option = st.selectbox(f"Select option to Fill:", ("Specific Value", "Drop"), key=col)
                    if option == "Specific Value":
                        value = st.text_input(f"Enter specific value for {col}", key=f"value_{col}")
                        if value and st.button(f"âœ… Confirm", key=f"confirm_{col}"):
                            df_missing[col].fillna(value, inplace=True)
                            st.success(f"âœ… Filled NaN values in **{col}** with **{value}**")
                    elif option == "Drop":
                        if st.button(f"âœ… Confirm Drop NaNs in {col}", key=f"drop_{col}"):
                            df_missing.dropna(subset=[col], inplace=True)
                            st.success(f"âœ… Dropped rows with NaN in **{col}**")

                # Numerical Columns
                else:  
                    option = st.selectbox(f"Select option to Fill:", 
                                        ("Mean", "Median", "Mode", "Interquartile Range (IQR)","Specific Value"), key=col)
                    if option == "Specific Value":
                        value = st.text_input(f"Enter specific value for {col}", key=f"num_value_{col}")
                        if value and st.button(f"âœ… Confirm", key=f"confirm_num_value_{col}"):
                            df_missing[col].fillna(float(value), inplace=True)
                            st.success(f"âœ… Filled NaN values in **{col}** with **{value}**")
                    elif st.button(f"âœ… Confirm", key=f"confirm_num_{col}"):
                        if option == "Mean":
                            df_missing[col].fillna(df_missing[col].mean(), inplace=True)
                            st.success(f"âœ… Filled NaN values in **{col}** with Mean")
                        elif option == "Median":
                            df_missing[col].fillna(df_missing[col].median(), inplace=True)
                            st.success(f"âœ… Filled NaN values in **{col}** with Median")
                        elif option == "Mode":
                            df_missing[col].fillna(df_missing[col].mode()[0], inplace=True)
                            st.success(f"âœ… Filled NaN values in **{col}** with Mode")
                        elif option == "Interquartile Range (IQR)":
                            Q1 = df_missing[col].quantile(0.25)
                            Q3 = df_missing[col].quantile(0.75)
                            IQR = Q3 - Q1
                            df_missing[col].fillna(df_missing[col].median(), inplace=True)  
                            st.success(f"âœ… Filled NaN values in **{col}** using IQR")

        st.write("ğŸ“Œ Updated Dataset Preview After Handling Missing Values:")
        st.dataframe(df_missing.head())

        # Store in session state to keep modifications
        st.session_state["df_processed"] = df_missing


       # ğŸ” INCONSISTENCY HANDLING
    elif preprocess == "ğŸ” Inconsistency":
        # Drop Unnecessary Columns
        st.header("ğŸ—‘ï¸ Drop Unnecessary Columns")
        columns_to_drop = st.multiselect("Select columns to drop", df.columns)
        drop_button = st.button("Drop Column")
        if drop_button:
            if columns_to_drop:
                df.drop(columns=columns_to_drop, inplace=True)
                st.success(f"âœ… Dropped columns: {', '.join(columns_to_drop)}")
                st.write("ğŸ“Œ Updated Dataset After Dropping Columns:")
                st.dataframe(df.head())

        # Choose Inconsistency Handling Method
        inconsistency_option = st.radio("ğŸ“Œ Choose Inconsistency Handling:", ("Data Type Conversion", "Filter/Search", "Replace Values", "Remove Char"))

        # Data Type Conversion Handling
        if inconsistency_option == "Data Type Conversion":
            with st.form("data_type_conversion_form"):
                column_to_convert = st.selectbox("ğŸ“Œ Select Column to Change Data Type", df.columns, key="inconsistency_col")
                new_dtype = st.selectbox("ğŸ”„ Convert Data Type To", ["int", "float", "string", "date"], key="dtype_selection")
                date_component = None
                if new_dtype == "date":
                    date_component = st.radio("ğŸ“Œ Extract Date Component", ["Full Date", "Year", "Month", "Day"], horizontal=True, key="date_component")
                submit_button = st.form_submit_button("âœ… Convert Data Type")

            if submit_button:
                if new_dtype == "int":
                    df[column_to_convert] = pd.to_numeric(df[column_to_convert], errors="coerce").astype("Int64")
                elif new_dtype == "float":
                    df[column_to_convert] = pd.to_numeric(df[column_to_convert], errors="coerce").astype("float")
                elif new_dtype == "string":
                    df[column_to_convert] = df[column_to_convert].astype("string")
                elif new_dtype == "date":
                    df[column_to_convert] = pd.to_datetime(df[column_to_convert], errors="coerce")
                    if date_component == "Year":
                        df[column_to_convert] = df[column_to_convert].dt.year
                    elif date_component == "Month":
                        df[column_to_convert] = df[column_to_convert].dt.month
                    elif date_component == "Day":
                        df[column_to_convert] = df[column_to_convert].dt.day

                st.success(f"âœ… Column **{column_to_convert}** converted to **{new_dtype}**")
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("ğŸ“Œ Updated Data Types")
                    st.write(df.dtypes)
                with col2:
                    st.subheader("ğŸ“Š Updated Data Preview")
                    st.dataframe(df)

        elif inconsistency_option == "Filter/Search":
            col1, col2 = st.columns(2)
            with col1:
                selected_col = st.selectbox("ğŸ” Select Column to Search/Filter", df.columns)
            with col2:           
                search_value = st.text_input("ğŸ” Enter value to search")
            if search_value:
                filtered_df = df[df[selected_col].astype(str).str.contains(search_value, case=False, na=False)]
                st.write(f"ğŸ“Œ **Filtered Results for '{search_value}' in {selected_col}:**")
                st.dataframe(filtered_df)

        elif inconsistency_option == "Replace Values":
            selected_col = st.selectbox("ğŸ›  Select Column to Replace Values", df.columns)
            col1, col2 = st.columns(2)
            with col1:
                old_value = st.text_input("âœï¸ Enter value to replace")
            with col2:
                new_value = st.text_input("âœ… Enter new value")
            if old_value and new_value:
                df[selected_col] = df[selected_col].replace(old_value, new_value)
                st.success(f"âœ… '{old_value}' replaced with '{new_value}' in column {selected_col}")
                st.dataframe(df.head())

        elif inconsistency_option == "Remove Char":
            st.dataframe(df)
            selected_col = st.selectbox("ğŸ›  Select Column to remove Values", df.columns)
            col1, col2 = st.columns(2)
            with col1:
                old_vl = st.text_input("âœï¸ Enter value to remove:")
            with col2:
                exp = st.text_input("Enter Regular expression:")

            if old_vl or exp:
                df[selected_col] = df[selected_col].apply(lambda x: np.nan if str(x) == old_vl or (exp and re.fullmatch(exp, str(x))) 
                                                        else str(x).replace(old_vl, '').strip() if old_vl 
                                                        else re.sub(exp, '', str(x)).strip())
                st.success(f"âœ… '{old_vl or exp}' removed from column {selected_col}")
                st.dataframe(df)
                st.write("ğŸ“Œ Updated Dataset Preview:")


#         elif inconsistency_option == "Custom Code":
#             st.dataframe(df)
#             st.subheader("ğŸ§‘â€ğŸ’» Write Your Custom Data Cleaning Code")
#             code_template = """
# # Example:
# # df['column_name'] = df['column_name'].str.strip()
# # df['date_column'] = pd.to_datetime(df['date_column'], errors='coerce')
# """
#             custom_code = st.text_area("Write your Python code here:", code_template, height=150)
#             if st.button("ğŸš€ Run Custom Code"):
#                 try:
#                     exec(custom_code, {"df": df, "pd": pd})
#                     st.success("âœ… Custom code executed successfully!")
#                     st.dataframe(df.head())
#                 except Exception as e:
#                     st.error(f"âŒ Error executing custom code: {e}")

#         st.session_state.df = df
#         st.session_state["df_processed"] = df

    elif preprocess == "custom code":
        st.dataframe(df)
        st.subheader("ğŸ§‘â€ğŸ’» Write Your Custom Data Cleaning Code")

        # ğŸ“ Code Template
        code_template = """
    # Example:
    # df['column_name'] = df['column_name'].str.strip()
    # df['date_column'] = pd.to_datetime(df['date_column'], errors='coerce')
    # print(df['name'].value_counts())  # Example to display output like Jupyter Notebook
    """

        # ğŸ“„ Text Area for Custom Code Input
        custom_code = st.text_area("Write your Python code here:", code_template, height=150)

        # ğŸ›ï¸ Output Display Options
        output_type = st.radio(
            "Select Output Type:",
            ("Text Output", "DataFrame Preview"),
            index=1
        )

        # ğŸš€ Run Code Button
        if st.button("ğŸš€ Run Code"):
            try:
                # ğŸ”„ Capture Standard Output
                output_buffer = io.StringIO()
                sys.stdout = output_buffer  # Redirect stdout to the buffer

                # ğŸ”„ Execute Code with Proper DataFrame Reference
                local_env = {"df": df, "pd": pd}

                # ğŸ§® Execute Custom Code
                exec(custom_code, {}, local_env)

                # âœ… Success Message
                st.success("âœ… Custom code executed successfully!")

                # ğŸ“„ Display Output Based on Selected Option
                if output_type == "Text Output":
                    st.write("### ğŸ“Š Code Output:")
                    output_text = output_buffer.getvalue()
                    if output_text:
                        st.text(output_text)
                    else:
                        st.info("â„¹ï¸ No text output to display.")
                
                elif output_type == "DataFrame Preview":
                    st.write("### ğŸ“‘ Updated DataFrame Preview:")
                    if "df" in local_env:
                        df = local_env["df"]
                        st.dataframe(df.head())
                    else:
                        st.warning("âš ï¸ DataFrame not modified or not found in custom code.")

            except Exception as e:
                st.error(f"âŒ Error executing custom code: {e}")

            finally:
                sys.stdout = sys.__stdout__  # Reset stdout to default

        # ğŸ’¾ Store Updated DataFrame in Session State
        st.session_state.df = df
        st.session_state["df_processed"] = df



    # **ğŸ“Š EDA Section (Only Runs if `preprocess == "EDA"`)**
    elif preprocess == "ğŸ“ˆ EDA":
       # **ğŸ“Š EDA Section (Only Runs if `preprocess == "EDA"`)**
        st.header("ğŸ“Š Exploratory Data Analysis")

        # Initialize session state for EDA plots
        if "eda_plots" not in st.session_state:
            st.session_state.eda_plots = []

        # **Step 1: Select Analysis Type**
        analysis_type = st.radio("ğŸ“Š Select Analysis Type", ["Univariate Analysis","Bi-variate Analysis" ,"Multivariate Analysis"], key="eda_type")

        # **Univariate Analysis**
        if analysis_type == "Univariate Analysis":
            col1, col2 = st.columns(2)
            with col1:
                selected_column = st.selectbox("ğŸ“Œ Select Column", df.columns, key="univar_col")
            with col2:
                chart_option = st.selectbox("ğŸ“Š Select Chart Type", ["Histogram", "Box Plot", "Bar Chart"], key="univar_chart")

            if st.button("â• Add Univariate Plot", key="add_univar"):
                st.session_state.eda_plots.append(("Univariate", selected_column, chart_option))

        # **bivariate Analysis**
        elif analysis_type == "Bi-variate Analysis":
            col1 ,col2 = st.columns(2)
            with col1:
                x_axis = st.selectbox("ğŸ“Œ Select X-Axis", df.columns, key="bi_x")
            with col2:
                y_axis = st.selectbox("ğŸ“Œ Select Y-Axis", df.columns, key="bi_y")
            multi_chart_option = st.selectbox("ğŸ“Š Select bivariate Chart Type", ["Scatter Plot", "Line Chart"], key="bi_chart")

            if st.button("â• Add Bi-variate Plot", key="add_bi"):
                st.session_state.eda_plots.append(("bivariate", x_axis, y_axis,multi_chart_option))
        
        # **Multivariate Analysis**
        elif analysis_type == "Multivariate Analysis":
            col1 ,col2 = st.columns(2)
            with col1:
                x_axis = st.selectbox("ğŸ“Œ Select X-Axis", df.columns, key="multi_x")
                hue = st.selectbox("ğŸ“Œ Select Hue column", df.columns, key="multi_hue")
            with col2:
                y_axis = st.selectbox("ğŸ“Œ Select Y-Axis", df.columns, key="multi_y")
            multi_chart_option = st.selectbox("ğŸ“Š Select Multivariate Chart Type", ["Scatter Plot", "Line Chart"], key="multi_chart")

            if st.button("â• Add Multivariate Plot", key="add_multi"):
                st.session_state.eda_plots.append(("Multivariate", x_axis, y_axis, hue,multi_chart_option))

        # **Step 3: Display All Selected Plots**
        for idx, plot in enumerate(st.session_state.eda_plots):
            fig, ax = plt.subplots()

            # Handle Univariate Analysis
            if plot[0] == "Univariate":
                analysis, col, chart = plot  # Unpack only 3 elements
                st.subheader(f"ğŸ“Š {chart} for {col}")

                if chart == "Histogram":
                    sns.histplot(df[col], kde=True, ax=ax)
                    plt.xticks(rotation='vertical')
                elif chart == "Box Plot":
                    sns.boxplot(x=df[col], ax=ax)
                elif chart == "Bar Chart":
                    df[col].value_counts().plot(kind="bar", ax=ax)
                    plt.xticks(rotation='vertical')
                    
            # Handle bivariate Analysis
            elif plot[0] == "bivariate":
                analysis, x_col, y_col,chart = plot  # Unpack 4 elements
                st.subheader(f"ğŸ“Š {chart} for {x_col} vs {y_col}")
                if chart == "Scatter Plot":
                    sns.scatterplot(x=df[x_col], y=df[y_col], ax=ax)
                    plt.xticks(rotation='vertical')
                        
                elif chart == "Line Chart":
                    sns.lineplot(x=df[x_col], y=df[y_col], ax=ax)
                    plt.xticks(rotation='vertical')

            # Handle Multivariate Analysis
            elif plot[0] == "Multivariate":
                analysis, x_col, y_col,hue,chart = plot  # Unpack 4 elements
                st.subheader(f"ğŸ“Š {chart} for {x_col} vs {y_col}")

                if chart == "Scatter Plot":
                    sns.scatterplot(x=df[x_col], y=df[y_col], ax=ax,hue=df[hue])
                    plt.xticks(rotation='vertical')
                        
                elif chart == "Line Chart":
                    sns.lineplot(x=df[x_col], y=df[y_col], ax=ax,hue=df[hue])
                    plt.xticks(rotation='vertical')
            
            st.pyplot(fig)

        # **Refresh Button**
        if st.button("ğŸ”„ Refresh EDA"):
            st.session_state.eda_plots = []  # Clear session state
            st.rerun()

        # FEATURE ENGINEERING
    elif preprocess == "âš™ï¸ Feature Eng":
        df_feature_eng = st.session_state.get("df_processed", df).copy()

        # Select Features to Encode
        st.header("ğŸ› ï¸ Encode Categorical Features")
        cat_features = st.multiselect("ğŸ“Š Select Features to Encode", 
                                      [col for col in df_feature_eng.columns if df_feature_eng[col].dtype == 'object'])
        
        # Encoding Categorical Features
        if cat_features:
            encoding_method = st.selectbox("Select Encoding Method", ("Label Encoding", "One-Hot Encoding"))
            encode_button = st.button("âœ…Confirm",key=f"{cat_features} is encodedâœ…")
            if encode_button:
                if encoding_method == "Label Encoding":
                    label_encoders = {}
                    for col in cat_features:
                        le = LabelEncoder()
                        df_feature_eng[col] = le.fit_transform(df_feature_eng[col].astype(str))
                        label_encoders[col] = le

                elif encoding_method == "One-Hot Encoding":
                    df_feature_eng = pd.get_dummies(df_feature_eng, columns=cat_features).replace({True:1,False:0})

                st.success("âœ… Categorical features encoded successfully!")
                st.write("ğŸ“Œ Updated Dataset After Encoding:")
                st.dataframe(df_feature_eng.head())

        # Feature Scaling
        st.header("ğŸ“ Feature Scaling")
        scale_features = st.multiselect("Select Features to Scale", df_feature_eng.columns)
        scale_button = st.button("âœ…Confirm",key=f"{scale_features} is scaledâœ…")
        if scale_button:
            if scale_features:
                scaler = StandardScaler()
                df_feature_eng[scale_features] = scaler.fit_transform(df_feature_eng[scale_features])
                st.write(f"âœ… Scaled Features: {', '.join(scale_features)}")

                st.success("âœ… Feature scaling applied successfully!")
                st.write("ğŸ“Œ Updated Dataset After Feature Scaling:")
                st.dataframe(df_feature_eng.head())

        # Store df_feature_eng in session_state for download
        st.session_state["df_feature_eng"] = df_feature_eng

    # ğŸ“¥ DOWNLOAD PROCESSED DATASET
    if "df_feature_eng" in st.session_state:
        df_to_download = st.session_state["df_feature_eng"]
        csv_buffer = io.StringIO()
        df_to_download.to_csv(csv_buffer, index=False)
        csv_data = csv_buffer.getvalue()

        st.header("ğŸ“¥ Download Processed Dataset")
        st.download_button(
            label="ğŸ“¥ Download CSV",
            data=csv_data,
            file_name="processed_dataset.csv",
            mime="text/csv"
        )

        st.success("âœ… Processed dataset is ready for download!")



    elif preprocess=='ğŸ¤– Train Model only':
         # # Selecting Features and Target
        target_column = st.selectbox("ğŸ¯ Select Target Column", df.columns)
        feature_columns = st.multiselect("ğŸ“Š Select Feature Columns", df.columns, default=[col for col in df.columns if col != target_column])

        if feature_columns and target_column:
            X = df[feature_columns]
            y = df[target_column]
        # Split dataset
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Sidebar: Choose Model Type
        model_type = st.sidebar.radio("Select Model Type", ("Regression", "Classification"))

        if model_type == "Regression":
            regressor_choice = st.sidebar.selectbox("Choose Regressor", ("CatBoost", "Stacking"))

            if regressor_choice == "CatBoost":
                # Sidebar: CatBoost Parameters
                st.sidebar.header("âš™ï¸ CatBoost Parameters")
                iterations = st.sidebar.number_input("Iterations", value=1000, step=10, format="%d")
                learning_rate = st.sidebar.number_input("Learning Rate", value=0.1, format="%.6f")
                l2_leaf_reg = st.sidebar.number_input("L2 Leaf Regularization", value=3.5, format="%.6f")
                depth = st.sidebar.number_input("Depth", 1, 16, 6, 1)

                if st.button("ğŸš€ Train Model"):
                    model = CatBoostRegressor(
                        iterations=iterations,
                        learning_rate=learning_rate,
                        depth=depth,
                        l2_leaf_reg=l2_leaf_reg,
                        verbose=0
                    )
                    model.fit(X_train, y_train, early_stopping_rounds=50, verbose=False)

                    y_pred = model.predict(X_test)
                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                    st.success(f"âœ… Model Trained Successfully! RMSE Score: {rmse:.6f}")
                    st.session_state["trained_model"] = model
                    st.session_state["feature_columns"] = feature_columns

            elif regressor_choice == "Stacking":
                base_learners = [
                    ("lr", LinearRegression()),
                    ("dt", DecisionTreeRegressor()),
                    ("rf", RandomForestRegressor())
                ]
                meta_learner = LinearRegression()
                model = StackingRegressor(estimators=base_learners, final_estimator=meta_learner)

                if st.button("ğŸš€ Train Model"):
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                    st.success(f"âœ… Model Trained Successfully! RMSE Score: {rmse:.6f}")
                    st.session_state["trained_model"] = model
                    st.session_state["feature_columns"] = feature_columns

        # Upload Test Dataset for Prediction
        st.header("2ï¸âƒ£ Upload Test Dataset for Prediction")
        test_file = st.file_uploader("Upload your test dataset (CSV) for predictions", type=["csv"])

        if test_file and "trained_model" in st.session_state:
            test_df = pd.read_csv(test_file)
            st.write("ğŸ“Œ Test Dataset Preview:")
            st.dataframe(test_df.head())

            missing_cols = [col for col in st.session_state["feature_columns"] if col not in test_df.columns]
            if missing_cols:
                st.error(f"âŒ Missing columns in test file: {missing_cols}")
            else:
                if st.button("ğŸ“Š Make Predictions"):
                    predictions = st.session_state["trained_model"].predict(test_df[st.session_state["feature_columns"]])
                    submission_df = pd.DataFrame({
                        "id": range(300000, 300000 + len(test_df)),
                        "submission": predictions
                    })

                    st.success("âœ… Predictions made successfully!")
                    st.write("ğŸ“Œ Preview of Submission File:")
                    st.dataframe(submission_df.head())

                    csv = submission_df.to_csv(index=False).encode('utf-8')
                    st.download_button("ğŸ“¥ Download Submission File", data=csv, file_name="submission.csv", mime="text/csv")